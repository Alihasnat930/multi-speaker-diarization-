# Multi-Speaker Identification Guide

## ğŸ¯ How It Works

Your system is **already configured for multi-speaker identification**. Here's what happens when you upload a conversation:

### 1. **Voice Activity Detection (VAD)**
   - Silero VAD model detects when people are speaking
   - Filters out silence, noise, and non-speech sounds
   - Identifies speech segments with precise timestamps

### 2. **Speaker Diarization** 
   - Separates audio into segments by different speakers
   - Uses spectral clustering on voice embeddings
   - Answers: "Who spoke when?"

### 3. **Speaker Recognition (Identification)**
   - ECAPA-TDNN model extracts voice embeddings (speaker fingerprints)
   - Compares embeddings to enrolled speakers
   - Assigns speaker IDs to each segment

### 4. **Speech-to-Text Transcription**
   - SpeechBrain ASR transcribes each speaker segment
   - Enhanced with dental terminology vocabulary
   - Produces text for each speaker turn

## ğŸ“Š Example Output

When you process a 2-person conversation, you'll get:

```json
{
  "segments": [
    {
      "start": 0.5,
      "end": 3.2,
      "speaker_id": "Speaker_0",
      "score": 0.85,
      "text": "Hello, how can I help you today?"
    },
    {
      "start": 3.5,
      "end": 6.8,
      "speaker_id": "Speaker_1", 
      "score": 0.92,
      "text": "I have some pain in my upper molar"
    },
    {
      "start": 7.0,
      "end": 10.5,
      "speaker_id": "Speaker_0",
      "score": 0.88,
      "text": "Let me examine that area"
    }
  ]
}
```

## ğŸª Current Issue: FFmpeg Missing

**Problem:** MP3/M4A files can't be processed without FFmpeg

**Solutions:**

### Option A: Install FFmpeg (Recommended)
See `INSTALL_FFMPEG.md` for detailed instructions:

**Quick install with Chocolatey:**
```powershell
choco install ffmpeg -y
```

**Or download manually:**
1. https://www.gyan.dev/ffmpeg/builds/
2. Extract to C:\ffmpeg
3. Add C:\ffmpeg\bin to PATH
4. Restart terminal

### Option B: Use WAV Files
- Convert your MP3 to WAV using online tools
- Upload WAV files directly
- System works perfectly with WAV files

## ğŸ­ Improving Speaker Identification

Right now, speakers are labeled as "Speaker_0", "Speaker_1", etc.

### To Get Named Speakers (e.g., "Dentist", "Patient"):

1. **Enroll Speakers** (one-time setup)
   
   Go to http://localhost:8000/docs and find `/enroll` endpoint:
   
   - Upload a 10-30 second audio sample of the dentist's voice
   - Set `speaker_id` = "Dentist"
   - Upload a sample of the patient's voice
   - Set `speaker_id` = "Patient"

2. **Or Use Python Script:**
   ```powershell
   python scripts/enroll_speaker.py --speaker-id Dentist --audio dentist_sample.wav
   python scripts/enroll_speaker.py --speaker-id Patient --audio patient_sample.wav
   ```

3. **Process New Audio:**
   - After enrollment, the system will match voices
   - Output will show "Dentist" and "Patient" instead of generic IDs
   - Matching confidence score indicates reliability

## ğŸ§ª Testing Multi-Speaker Identification

### Test with your own audio:
```powershell
python test_speaker_id.py your_conversation.wav
```

### What to expect:
- âœ… Number of speakers detected
- âœ… Speaker IDs for each segment
- âœ… Timestamps and transcriptions
- âœ… Confidence scores (0-1)

## ğŸ“ Tips for Best Results

1. **Audio Quality:**
   - Clear recording, minimal background noise
   - 16kHz or higher sample rate
   - Each speaker should speak for at least 2-3 seconds per turn

2. **File Formats:**
   - WAV: âœ… Works immediately
   - FLAC: âœ… Works immediately
   - MP3: âš ï¸ Needs FFmpeg
   - M4A: âš ï¸ Needs FFmpeg

3. **Speaker Enrollment:**
   - Use clean samples (no overlapping speech)
   - 10-30 seconds per speaker is ideal
   - More samples = better accuracy

4. **Conversation Length:**
   - Minimum: 30 seconds (for meaningful diarization)
   - Optimal: 2-10 minutes
   - Maximum: Limited by system memory

## ğŸ”§ Current Status

| Feature | Status |
|---------|--------|
| Multi-speaker detection | âœ… Working |
| Voice activity detection | âœ… Working |
| Speaker diarization | âœ… Working |
| Speaker identification | âœ… Working |
| Speech-to-text | âœ… Working |
| Dental terminology | âœ… Working |
| Speaker enrollment | âœ… Working |
| MP3/M4A support | âš ï¸ Needs FFmpeg |
| WAV/FLAC support | âœ… Working |
| SOAP note generation | â¸ï¸ Disabled |

## ğŸš€ Quick Start

1. **Install FFmpeg** (if you have MP3/M4A files):
   ```powershell
   choco install ffmpeg -y
   ```

2. **Restart the server** (in the server terminal window):
   - Press Ctrl+C
   - Run: `START_SERVER.bat`

3. **Upload your audio file** at http://localhost:8000

4. **View results:**
   - See all speaker segments
   - Each with speaker ID, timestamp, and transcription
   - Multiple speakers automatically identified

## ğŸ†˜ Troubleshooting

**"System cannot find file specified"**
- Install FFmpeg for MP3/M4A files
- Or use WAV format instead

**"Only detecting 1 speaker"**
- Audio might have very similar voices
- Try enrolling speakers first
- Check if both speakers are speaking clearly

**"Speaker IDs keep changing"**
- Enroll speakers for consistent naming
- Without enrollment, IDs are assigned dynamically

**"Low confidence scores"**
- Audio quality might be poor
- Background noise affecting recognition
- Try enrolling with cleaner samples

## ğŸ“š Next Steps

1. Install FFmpeg following `INSTALL_FFMPEG.md`
2. Restart your server
3. Upload a multi-person conversation
4. See automatic speaker separation in action!
